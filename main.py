import os
import re
import io
import csv
import json
import tempfile
from typing import Optional, Dict, Any, List

import httpx
import pandas as pd
import pdfplumber
from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel, Field

APP_NAME = "MyTaxLead AI Worker"
app = FastAPI(title=APP_NAME)

AI_WORKER_TOKEN = os.getenv("AI_WORKER_TOKEN", "").strip()

# Optional: allow only your domain for signed downloads (recommended)
SIGNED_URL_ALLOWLIST = os.getenv("SIGNED_URL_ALLOWLIST", "mytaxlead.com").strip()


class AnalyzeRequest(BaseModel):
    # You will pass a signed download URL generated by your PHP (ai_signed_download.php)
    signed_url: str = Field(..., description="Signed URL pointing to a file download endpoint")
    stored_name: Optional[str] = Field(None, description="Your stored file name (for logging)")
    original_name: Optional[str] = Field(None, description="Original file name (optional)")
    mime: Optional[str] = Field(None, description="Mime type if known (optional)")
    client_id: Optional[int] = Field(None, description="Client ID (optional)")
    upload_id: Optional[int] = Field(None, description="Upload row ID (optional)")


def _require_bearer(req: Request):
    """Require Authorization: Bearer <AI_WORKER_TOKEN>"""
    if not AI_WORKER_TOKEN:
        raise HTTPException(status_code=500, detail="AI_WORKER_TOKEN not set on Railway")
    auth = req.headers.get("authorization", "")
    if not auth.lower().startswith("bearer "):
        raise HTTPException(status_code=401, detail="Missing bearer token")
    token = auth.split(" ", 1)[1].strip()
    if token != AI_WORKER_TOKEN:
        raise HTTPException(status_code=403, detail="Invalid token")


def _host_allowed(url: str) -> bool:
    # Very simple allowlist check
    try:
        from urllib.parse import urlparse
        host = urlparse(url).hostname or ""
        return host.endswith(SIGNED_URL_ALLOWLIST)
    except Exception:
        return False


async def _download_to_tempfile(url: str) -> str:
    if SIGNED_URL_ALLOWLIST and not _host_allowed(url):
        raise HTTPException(status_code=400, detail="signed_url host not allowed")

    timeout = httpx.Timeout(60.0, connect=15.0)
    async with httpx.AsyncClient(timeout=timeout, follow_redirects=True) as client:
        r = await client.get(url)
        if r.status_code != 200:
            raise HTTPException(status_code=400, detail=f"Download failed ({r.status_code})")
        data = r.content

    # Size guard: 20MB max
    if len(data) > 20 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="File too large (max 20MB)")

    fd, path = tempfile.mkstemp(prefix="mtl_", suffix=".bin")
    with os.fdopen(fd, "wb") as f:
        f.write(data)
    return path


def _sniff_ext(name: str) -> str:
    name = (name or "").lower().strip()
    if "." in name:
        return name.rsplit(".", 1)[-1]
    return ""


def _extract_pdf_text(path: str) -> str:
    out = []
    with pdfplumber.open(path) as pdf:
        for page in pdf.pages[:50]:  # guard
            txt = page.extract_text() or ""
            if txt.strip():
                out.append(txt)
    return "\n".join(out).strip()


def _extract_csv_text(path: str) -> str:
    # Read first 10k lines safely
    out = []
    with open(path, "rb") as fb:
        raw = fb.read()
    # Try common encodings
    for enc in ("utf-8", "utf-8-sig", "latin-1"):
        try:
            s = raw.decode(enc)
            break
        except Exception:
            s = None
    if not s:
        return ""
    lines = s.splitlines()[:10000]
    return "\n".join(lines)


def _extract_excel_text(path: str) -> str:
    # Read first sheets and first N rows
    out = []
    xls = pd.ExcelFile(path)
    for sheet in xls.sheet_names[:5]:
        df = xls.parse(sheet)
        if df is None or df.empty:
            continue
        df = df.head(200)  # guard
        out.append(f"--- SHEET: {sheet} ---")
        out.append(df.to_csv(index=False))
    return "\n".join(out).strip()


def _basic_figures_from_text(text: str) -> Dict[str, Any]:
    """
    Not "AI accounting" yet â€” just quick extraction you can use immediately.
    We'll upgrade later to proper statement parsing + AI categorisation.
    """
    if not text:
        return {"has_text": False, "numbers_found": 0, "totals": {}}

    # Find money-like numbers (e.g., 1,234.56 or 1234.56 or 1234)
    nums = re.findall(r"[-+]?\d{1,3}(?:,\d{3})*(?:\.\d{2})?|[-+]?\d+(?:\.\d{2})?", text)
    cleaned = []
    for n in nums[:5000]:  # guard
        try:
            cleaned.append(float(n.replace(",", "")))
        except Exception:
            pass

    # Basic summaries
    positives = [x for x in cleaned if x > 0]
    negatives = [x for x in cleaned if x < 0]

    return {
        "has_text": True,
        "numbers_found": len(cleaned),
        "totals": {
            "sum_all": round(sum(cleaned), 2),
            "sum_positive": round(sum(positives), 2),
            "sum_negative": round(sum(negatives), 2),
            "count_positive": len(positives),
            "count_negative": len(negatives),
        }
    }


@app.get("/")
async def root():
    return {"ok": True, "service": APP_NAME}


@app.get("/health")
async def health():
    return {"ok": True}


@app.post("/analyze")
async def analyze(req: Request, payload: AnalyzeRequest):
    """
    Your PHP admin area will call this endpoint AFTER a customer uploads a file.
    You pass a signed_url so Railway can download the private file securely.
    """
    _require_bearer(req)

    # Download
    tmp_path = await _download_to_tempfile(payload.signed_url)

    try:
        # Decide file type
        ext = _sniff_ext(payload.original_name or payload.stored_name or "")
        mime = (payload.mime or "").lower()

        text = ""

        # Prefer extension, fallback to mime
        if ext in ("pdf",) or "pdf" in mime:
            text = _extract_pdf_text(tmp_path)
            kind = "pdf"
        elif ext in ("csv", "txt") or "csv" in mime or "text" in mime:
            text = _extract_csv_text(tmp_path)
            kind = "csv"
        elif ext in ("xlsx", "xls") or "excel" in mime or "spreadsheet" in mime:
            text = _extract_excel_text(tmp_path)
            kind = "excel"
        else:
            # Try pdf first then csv as fallback
            try:
                text = _extract_pdf_text(tmp_path)
                kind = "pdf"
            except Exception:
                text = _extract_csv_text(tmp_path)
                kind = "text"

        figures = _basic_figures_from_text(text)

        # Short preview (avoid returning huge text)
        preview = text[:1500] if text else ""

        return {
            "ok": True,
            "kind": kind,
            "stored_name": payload.stored_name,
            "original_name": payload.original_name,
            "client_id": payload.client_id,
            "upload_id": payload.upload_id,
            "figures": figures,
            "preview": preview
        }

    finally:
        try:
            os.unlink(tmp_path)
        except Exception:
            pass